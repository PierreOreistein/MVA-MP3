{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:15:50.838721Z",
     "start_time": "2019-02-26T22:15:48.291680Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, \\\n",
    "                         Reshape, BatchNormalization, Flatten\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:16:03.905531Z",
     "start_time": "2019-02-26T22:16:03.901704Z"
    }
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:16:06.930040Z",
     "start_time": "2019-02-26T22:16:06.923635Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self, e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self, s, train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ***act*** represents basically the policy. Indeed, according to the current state s, act returns the action the ```Agent``` must use. Here, the function ***act*** is divided in two steps. During the training step, the function ***act*** is a trade-off between exploration and exploitation. The goal of epsilon is precisely to explore more state: the ```Agent``` is going to use a random action with probability epsilon. Otherwise, the ```Agent``` uses the learned policy (***learned_act***). Therefore, the goal of epsilon is to encourage the exploration during the training period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:17:13.344734Z",
     "start_time": "2019-02-26T22:17:13.322240Z"
    }
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size + 4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size, grid_size))\n",
    "        self.position = np.zeros((grid_size, grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale = 16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time + 2, grid_size * self.scale, \n",
    "                                 grid_size * self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self, e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size, self.grid_size, 3)) + 128\n",
    "        b[self.board > 0, 0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x, self.y, :] = 256\n",
    "        b[-2:, :, :] = 0\n",
    "        b[:, -2:, :] = 0\n",
    "        b[:2, :, :] = 0\n",
    "        b[:, :2, :] = 0\n",
    "        \n",
    "        b = cv2.resize(b, None, fx=self.scale, fy=self.scale, \n",
    "                       interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t, :, :, :] = b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2, :]= -1\n",
    "        self.position[:, 0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        \n",
    "        if action == 0: # Going up (or down on the image)\n",
    "            if self.x == self.grid_size - 3:\n",
    "                self.x = self.x - 1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1: # Going up on the image\n",
    "            if self.x == 2:\n",
    "                self.x = self.x + 1\n",
    "            else:\n",
    "                self.x = self.x - 1\n",
    "        elif action == 2: # Going right on the image\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3: # Going left on the image\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size, 1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size, 1)),\n",
    "                               axis=2)\n",
    "        state = state[self.x-2:self.x+3, self.y-2:self.y+3, :]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time + 2, self.grid_size * self.scale, \n",
    "                                 self.grid_size * self.scale, 3))\n",
    "\n",
    "        malus[bonus > 0] = 0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x, self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)), \n",
    "                               axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:17:14.934734Z",
     "start_time": "2019-02-26T22:17:14.930933Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T = 200\n",
    "temperature = 0.3\n",
    "epochs_train = 21 # set small when debugging\n",
    "epochs_test = 15 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{itemize}\n",
    "    \\item The position array represents the position of the rat on the grid. One particular aspect is the border: the 2 first / last rows and columns are considered as walls and cannot be access. Therefore, the value of position for these cases are defined as -1. The position where is the rat is valued at 1.\n",
    "    \\item The board array represents the different rewards that the rat can obtain for every cases of the grid. Typically, the board value is equal to 0.5 where there is cheese, equal to -1 where there is poison and 0 otherwise.\n",
    "\\end{itemize}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:17:41.811747Z",
     "start_time": "2019-02-26T22:17:41.808334Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        \"\"\"Return a rabdom action.\"\"\"\n",
    "        \n",
    "        action = np.random.randint(0, 4, 1)[0]\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:17:44.879159Z",
     "start_time": "2019-02-26T22:17:44.872942Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(agent, env, epochs, prefix='', display=True, save=True):\n",
    "    \"\"\"Visualise the moves of the rat\"\"\"\n",
    "    \n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "\n",
    "        # Initialisation of win and lose\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "\n",
    "        while not game_over:\n",
    "            \n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "#             loss = agent.reinforce(prev_state, state, action, reward, game_over)\n",
    "            \n",
    "        # Save as a mp4\n",
    "        if save:\n",
    "            env.draw(prefix + str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "        \n",
    "        if display:\n",
    "            print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "                  .format(win, lose, score / epochs))\n",
    "        \n",
    "    if display:\n",
    "        print('Final score: ' + str(score/epochs))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:17:53.746622Z",
     "start_time": "2019-02-26T22:17:46.226191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 10.0/19.0. Average score (-0.6)\n",
      "Win/lose count 6.5/22.0. Average score (-1.6333333333333333)\n",
      "Win/lose count 7.0/12.0. Average score (-1.9666666666666666)\n",
      "Win/lose count 7.0/10.0. Average score (-2.1666666666666665)\n",
      "Win/lose count 5.0/13.0. Average score (-2.7)\n",
      "Win/lose count 7.0/18.0. Average score (-3.433333333333333)\n",
      "Win/lose count 11.5/16.0. Average score (-3.7333333333333334)\n",
      "Win/lose count 8.0/14.0. Average score (-4.133333333333334)\n",
      "Win/lose count 6.0/6.0. Average score (-4.133333333333334)\n",
      "Win/lose count 9.5/16.0. Average score (-4.566666666666666)\n",
      "Win/lose count 10.0/11.0. Average score (-4.633333333333334)\n",
      "Win/lose count 10.5/14.0. Average score (-4.866666666666666)\n",
      "Win/lose count 9.0/16.0. Average score (-5.333333333333333)\n",
      "Win/lose count 9.5/8.0. Average score (-5.233333333333333)\n",
      "Win/lose count 7.5/11.0. Average score (-5.466666666666667)\n",
      "Final score: -5.466666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T, temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent, env, epochs_test, prefix='./Results/random')\n",
    "HTML(display_videos('./Results/random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{itemize}\n",
    "    \\item The first result represents the Bellman equation. Let's prove it.\n",
    "    We denote by $(S_t)$ and $(A_t)$ the series of random variables representing the states and action over time. Therefore, if we take up the notations of the slides of the course, it has:\n",
    "    \\begin{align*}\n",
    "        Q^{\\pi}(s_t, a_t) &= \\mathbb{E}_{\\pi} \\left[ \\sum_{k=0}^{+\\infty} \\gamma^k * r(s_{t + k}, a_{t + k}) ~ \\big| ~ S_t=s_t, A_t=a_t \\right] \\\\\n",
    "        &= r(s_t, a_t) + \\gamma \\mathbb{E}_{\\pi} \\left[ \\sum_{k=0}^{+\\infty} \\gamma^k * r(s_{(t + 1) + k}, a_{(t + 1) + k}) ~ \\big| ~ S_t=s_t, A_t=a_t \\right] \\\\\n",
    "        &= r(s_t, a_t) + \\gamma \\mathbb{E}_{\\pi} \\left[ \\sum_{s_{t+1}, a_{t+1}} \\mathbf{1}_{ \\{ S_{t+1} = s_{t+1}, A_{t+1} = a_{t+1} \\} } \\underbrace{\\mathbb{E}_{\\pi} \\left[ \\sum_{k=0}^{+\\infty} \\gamma^k * r(s_{(t + 1) + k}, a_{(t + 1) + k}) ~ \\big| ~ S_{t+1}=s_{t+1}, A_{t+1}=a_{t+1} \\right]}_{ = Q^{\\pi}(s_{t+1}, a_{t+1})} ~ \\big| ~ S_t=s_t, A_t=a_t \\right] \\\\\n",
    "        &= r(s_t, a_t) + \\gamma \\sum_{s_{t+1}, a_{t+1}} \\mathbb{P}^{\\pi}\\left(S_{t+1}=s_{t+1}, A_{t+1}=a_{t+1} ~ | ~ S_t=s_t, A_t=a_t \\right) Q^{\\pi}(s_{t+1}, a_{t+1}) \\\\\n",
    "        &= r(a_t, s_t) + \\gamma \\mathbb{E}_{(s_{t+1}, a_{t+1}) \\sim p(.,. | s_t, a_t)} \\left[ Q^{\\pi}(s_{t+1}, a_{t+1}) \\right]\n",
    "    \\end{align*}\n",
    "    Moreover, these results are true for every $t$. So, it obtains the result.   \n",
    "    \\item This second equation corresponds to the Optimal Bellman Equation. Let's prove it: If it uses again the same equations with $Q^*$, it has:\n",
    "    \\begin{align*}\n",
    "    Q^{*}(s_t, a_t) &= r(s_t, a_t) + \\gamma \\sum_{s_{t+1}, a_{t+1}} \\mathbb{P}^{\\pi^*}\\left(S_{t+1}=s_{t+1}, A_{t+1}=a_{t+1} ~ | ~ S_t=s_t, A_t=a_t \\right) Q^{*}(s_{t+1}, a_{t+1}) \\\\\n",
    "    &= r(s_t, a_t) + \\gamma \\sum_{s_{t+1}, a_{t+1}} \\mathbb{P}\\left(S_{t+1}=s_{t+1} ~ | ~ S_t=s_t, A_t=a_t \\right) \\pi^*(a_{t+1} ~ | ~ S_{t+1} = s_{t+1}) Q^{*}(s_{t+1}, a_{t+1})\n",
    "    \\end{align*}\n",
    "    But, by definition of the optimal policy, \n",
    "    \\begin{equation*}\n",
    "        \\pi^*(a_{t+1} ~ | ~ S_{t+1} = s_{t+1}) = \\left\\{ \\begin{array}{ cl}\n",
    "                                                            \\frac{1}{|\\text{argmax}_{a} Q^{*}(s_{t+1}, a)|}, & \\text{if} ~ a_{t+1} \\in \\text{argmax}_{a} Q^{*}(s_{t+1}, a) \\\\\n",
    "                                                            0, & \\text{otherwise}\n",
    "                                                          \\end{array}\n",
    "                                                  \\right.\n",
    "   \\end{equation*}\n",
    "  Therefore:\n",
    "   \\begin{align*}\n",
    "    Q^{*}(s_t, a_t) &= r(s_t, a_t) + \\gamma \\sum_{s_{t+1}} \\mathbb{P}\\left(S_{t+1}=s_{t+1} ~ | ~ S_t=s_t, A_t=a_t \\right) max_{a_{t+1}} Q^{*}(s_{t+1}, a_{t+1}) \\\\\n",
    "    &= r(a_t, s_t) + \\gamma \\mathbb{E}_{s_{t+1} \\sim p(. | s_t, \\pi^*(.|s_t))} \\left[ \\max_{a_{t+1}} Q^{*}(s_{t+1}, a_{t+1}) \\right]\n",
    "    \\end{align*}\n",
    "    And as before, the result does not depend on the time $t$. It obtains theferore the result.\n",
    "    \\item So,now let suppose that we succeed to parametrised Q by a parameter $\\theta$. So, if it is looking for the the optimal policy $\\pi^*$, it corresponds to find $\\theta$ such that the previous equation on Q is respected. So, we would like to find theta such the two terms of the previous equation are as close as possible. Therefore, we can compute:\n",
    "    \\begin{align*}\n",
    "        \\mathcal{L}_1(\\theta) &= \\Vert E_{s' \\sim \\pi^*(.|s,a)} \\left[ r + \\gamma \\max_{a'}Q(s',a',\\theta) \\right] - Q(s, a, \\theta) \\Vert^2 \\\\\n",
    "        &= \\Vert E_{s' \\sim \\pi^*(.|s,a)} \\left[ r + \\gamma \\max_{a'}Q(s',a',\\theta) - Q(s, a, \\theta) \\right] \\Vert^2 \\\\\n",
    "        &\\leq E_{s' \\sim \\pi^*(.|s,a)} \\left[ \\Vert r + \\gamma \\max_{a'}Q(s',a',\\theta) - Q(s, a, \\theta) \\Vert^2 \\right], ~~~ \\text{by Jensen inequality} \\\\\n",
    "        &\\leq \\mathcal{L}(\\theta)\n",
    "    \\end{align*}\n",
    "    So $\\mathcal{L}(\\theta)$ can be used as pausible objective.\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:21:52.775292Z",
     "start_time": "2019-02-26T22:21:52.769673Z"
    }
   },
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        \"\"\"Store (s_t, a_t, s_t+1, r_t, game_over_t).\"\"\"\n",
    "        \n",
    "        # Current length of the memory\n",
    "        n = len(self.memory)\n",
    "        \n",
    "        # Append the new state\n",
    "        if n < self.max_memory:\n",
    "            self.memory.append(m)\n",
    "        else:\n",
    "            # Replace a random state\n",
    "            idx = np.random.choice(np.arange(n))\n",
    "            self.memory[idx] = m\n",
    "\n",
    "    def random_access(self):\n",
    "        \"\"\"Extract a random quintuplet (s_t, a_t, s_t+1, r_t, game_over_t) in memory.\"\"\"\n",
    "        \n",
    "        # Current length of the memory\n",
    "        n = len(self.memory)\n",
    "        \n",
    "        # Choose a random index\n",
    "        idx = np.random.choice(np.arange(n))\n",
    "        quintuplet = self.memory[idx]\n",
    "        \n",
    "        return quintuplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:21:54.211238Z",
     "start_time": "2019-02-26T22:21:54.204161Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(agent, env, epoch, prefix='', display=True, save=True):\n",
    "    \"\"\"Train the agent on env for the given number of epoch.\"\"\"\n",
    "    \n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix + str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "        \n",
    "        if display:\n",
    "            print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "                  .format(e + 1, epoch, loss, win, lose, win-lose))\n",
    "        \n",
    "        if save:\n",
    "            agent.save(name_weights=prefix + 'model.h5', name_model=prefix + 'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:22:01.997581Z",
     "start_time": "2019-02-26T22:22:01.976958Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon=0.1, memory_size=100, batch_size=16, n_state=2):\n",
    "        \"\"\"Initialisation of Deep Q Network.\"\"\"\n",
    "        super().__init__(epsilon=epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        # Grid size\n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        \"\"\"Choose the action according the current model.\"\"\"\n",
    "        \n",
    "        # Reshape the state\n",
    "        s_t = s.reshape(1, 5, 5, self.n_state)\n",
    "        \n",
    "        # Choose the maximising action\n",
    "        a_t = np.argmax(self.model.predict(s_t))\n",
    "        if a_t < 0:\n",
    "            print(a_t)\n",
    "        \n",
    "        return a_t\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        \"\"\"Two steps: first memorize the states, second learn from the pool.\"\"\"\n",
    "\n",
    "        # First Step\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        # Second Step\n",
    "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state)) #5, self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 2), dtype=np.dtype(float, int))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            # Sample a random transition\n",
    "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
    "            \n",
    "            # Add this state in input states\n",
    "            input_states[i, :, :, :] = s_\n",
    "            \n",
    "            if game_over_:\n",
    "                target_q[i, :] = r_\n",
    "            else:\n",
    "                n_s_ = n_s_.reshape(1, 5, 5, self.n_state)\n",
    "                target_q[i, :] = [r_ + self.discount * np.max(self.model.predict(n_s_)), a_]\n",
    "        \n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -5, 5)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self, name_weights='model.h5', name_model='model.json'):\n",
    "        \n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        \n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self, name_weights='model.h5', name_model='model.json'):\n",
    "        \n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "            \n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "    # Custom loss\n",
    "    def my_loss(self, data, y_pred):\n",
    "        \"\"\"Compute the mse between y_j and Q(s_j, a_j).\"\"\"\n",
    "\n",
    "        # Length\n",
    "        n = np.shape(y_pred)[0]\n",
    "\n",
    "        # Extract the corresponding y_pred\n",
    "        idx = tf.reshape(K.cast(data[:, 1], tf.int32), (-1, 1))\n",
    "        index = tf.concat([tf.reshape(tf.range(0, self.batch_size), (-1, 1)), idx], axis=1)\n",
    "        y_pred_2 = tf.gather_nd(y_pred, index)\n",
    "        y_true = data[:, 0]\n",
    "\n",
    "        return tf.losses.mean_squared_error(y_true, y_pred_2)\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5, 5, self.n_state, )))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), self.my_loss)\n",
    "        self.model = model\n",
    "        \n",
    "#         print(model.summary())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:30:37.571001Z",
     "start_time": "2019-02-26T22:22:09.732881Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/021 | Loss 0.0112 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 002/021 | Loss 0.0395 | Win/lose count 4.5/5.0 (-0.5)\n",
      "Epoch 003/021 | Loss 0.0241 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 004/021 | Loss 0.0283 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 005/021 | Loss 0.0189 | Win/lose count 6.5/4.0 (2.5)\n",
      "Epoch 006/021 | Loss 0.0279 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 007/021 | Loss 0.0224 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 008/021 | Loss 0.0142 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 009/021 | Loss 0.0127 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 010/021 | Loss 0.0163 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 011/021 | Loss 0.0182 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 012/021 | Loss 0.0198 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 013/021 | Loss 0.0130 | Win/lose count 7.0/3.0 (4.0)\n",
      "Epoch 014/021 | Loss 0.0215 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 015/021 | Loss 0.0187 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 016/021 | Loss 0.0351 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 017/021 | Loss 0.0300 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 018/021 | Loss 0.0182 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 019/021 | Loss 0.0221 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 020/021 | Loss 0.0277 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 021/021 | Loss 0.0170 | Win/lose count 2.0/2.0 (0.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=1, epsilon=0.1, memory_size=1000, batch_size=128)\n",
    "train(agent, env, epochs_train, prefix='./Results/fc_train')\n",
    "HTML(display_videos('./Results/fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:32:11.425070Z",
     "start_time": "2019-02-26T22:32:11.400403Z"
    }
   },
   "outputs": [],
   "source": [
    "def GridSearch(dqn, train_function=train, env=env):\n",
    "    \"\"\"Do a gridsearch on the following parameters: batch_size, memory_size, lr.\n",
    "       \"\"\"\n",
    "    \n",
    "    # Possible values of the optimising parameters\n",
    "    batch_size_l = [64]\n",
    "    memory_size_l = [1000]\n",
    "    lr_l = [1, 0.1, 0.01, 0.001]\n",
    "    \n",
    "    # Initialisation of best parameters\n",
    "    best_parameters = [0, 0, 0]\n",
    "    max_score = -float(\"inf\")\n",
    "    i = 0\n",
    "    \n",
    "    # Gridsearch\n",
    "    for batch_size in batch_size_l:\n",
    "        for memory_size in memory_size_l:\n",
    "            for lr in lr_l:\n",
    "                \n",
    "                # Definition of the agent\n",
    "                agent = dqn(batch_size, memory_size, lr)\n",
    "                \n",
    "                # Training of the agent\n",
    "                train_function(agent, env, epochs_train, prefix='./Results/fc_train_' + str(i) + \"_\",\n",
    "                               display=False, save=False)\n",
    "                \n",
    "                # Testing of the agent\n",
    "                score_test = test(agent, env, epochs_test,\n",
    "                                  prefix='./Results/fc_test_' + str(i),\n",
    "                                  display=False, save=False)\n",
    "                \n",
    "                # Update of best parameters\n",
    "                if max_score < score_test:\n",
    "                    max_score = score_test\n",
    "                    best_parameters = [batch_size, memory_size, lr]                \n",
    "                    print(\"New best score:\", score_test)\n",
    "                    print(\"Best parameters:\", best_parameters)\n",
    "                # Update of i\n",
    "                i += 1\n",
    "                n = len(batch_size_l) * len(memory_size_l) * len(lr_l)\n",
    "                print(\"Step done: \", i / n * 100)\n",
    "    \n",
    "    # Display best parameters\n",
    "    print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:32:49.693009Z",
     "start_time": "2019-02-26T22:32:11.949317Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Definition of the environment\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "\n",
    "# Definition of the agent\n",
    "dqn = lambda batch_size, memory_size, lr: DQN_CNN(size, lr=lr, epsilon=0.1,\n",
    "                                                  memory_size=memory_size,\n",
    "                                                  batch_size=batch_size)\n",
    "\n",
    "# Compute the GridSearch\n",
    "GridSearch(dqn, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For obtaining the best results, I implemented a GridSearch over different values of the following parameters:\n",
    "\\begin{itemize}\n",
    "    \\item batch_size\n",
    "    \\item memory_size\n",
    "    \\item learning_rate\n",
    "\\end{itemize}\n",
    "It seems that the two first parameters do not have a big impact for the environment selected. However, it seems that a big learning rate is required.\n",
    "\n",
    "Also, we implemented the loss in the function \"my_loss\" which correspond to:\n",
    "\\begin{equation}\n",
    "    \\sum_{i=1}^N (Q(s_i, s_a) - y_i)^2, ~~ \\text{with} ~~ y_i = \\left\\{\\begin{array}{cl}\n",
    "                                                                           r_i & \\text{if} ~ \\text{game_over} = True \\\\\n",
    "                                                                           r_i + \\max_{a'} Q({s'}_i, a') & \\text{otherwise}\n",
    "                                                                       \\end{array}\n",
    "                                                                \\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:33:06.239728Z",
     "start_time": "2019-02-26T22:33:06.233918Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args, lr=0.1, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        ## CNN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(5, 5, self.n_state, )))\n",
    "        model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), self.my_loss)\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:44:58.813807Z",
     "start_time": "2019-02-26T22:33:06.859273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/021 | Loss 0.0390 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 002/021 | Loss 0.0572 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 003/021 | Loss 0.0604 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 004/021 | Loss 0.0165 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 005/021 | Loss 0.0126 | Win/lose count 2.5/6.0 (-3.5)\n",
      "Epoch 006/021 | Loss 0.0129 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 007/021 | Loss 0.0187 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 008/021 | Loss 0.0166 | Win/lose count 6.5/5.0 (1.5)\n",
      "Epoch 009/021 | Loss 0.0229 | Win/lose count 6.0/4.0 (2.0)\n",
      "Epoch 010/021 | Loss 0.0130 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 011/021 | Loss 0.0360 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 012/021 | Loss 0.0171 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 013/021 | Loss 0.0170 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 014/021 | Loss 0.0159 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 015/021 | Loss 0.0190 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 016/021 | Loss 0.0221 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 017/021 | Loss 0.0235 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 018/021 | Loss 0.0245 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 019/021 | Loss 0.0199 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 020/021 | Loss 0.0204 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 021/021 | Loss 0.0256 | Win/lose count 9.0/0 (9.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=1, epsilon=0.1, memory_size=1000, batch_size=128)\n",
    "train(agent,env,epochs_train,prefix='./Results/cnn_train')\n",
    "HTML(display_videos('./Results/cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:45:25.433359Z",
     "start_time": "2019-02-26T22:44:58.820606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 3.0/3.0. Average score (0.0)\n",
      "Win/lose count 3.0/0. Average score (0.2)\n",
      "Win/lose count 2.0/2.0. Average score (0.2)\n",
      "Win/lose count 2.5/2.0. Average score (0.23333333333333334)\n",
      "Win/lose count 2.5/1.0. Average score (0.3333333333333333)\n",
      "Win/lose count 2.5/1.0. Average score (0.43333333333333335)\n",
      "Win/lose count 2.0/4.0. Average score (0.3)\n",
      "Win/lose count 2.5/1.0. Average score (0.4)\n",
      "Win/lose count 2.5/1.0. Average score (0.5)\n",
      "Win/lose count 3.0/1.0. Average score (0.6333333333333333)\n",
      "Win/lose count 1.0/1.0. Average score (0.6333333333333333)\n",
      "Win/lose count 3.0/3.0. Average score (0.6333333333333333)\n",
      "Win/lose count 0.5/0. Average score (0.6666666666666666)\n",
      "Win/lose count 3.5/1.0. Average score (0.8333333333333334)\n",
      "Win/lose count 3.0/0. Average score (1.0333333333333334)\n",
      "Final score: 1.0333333333333334\n",
      "\n",
      "Test of the FC\n",
      "Win/lose count 2.0/0. Average score (0.13333333333333333)\n",
      "Win/lose count 1.0/1.0. Average score (0.13333333333333333)\n",
      "Win/lose count 2.0/1.0. Average score (0.2)\n",
      "Win/lose count 1.5/2.0. Average score (0.16666666666666666)\n",
      "Win/lose count 1.5/1.0. Average score (0.2)\n",
      "Win/lose count 0/4.0. Average score (-0.06666666666666667)\n",
      "Win/lose count 4.0/4.0. Average score (-0.06666666666666667)\n",
      "Win/lose count 0.5/0. Average score (-0.03333333333333333)\n",
      "Win/lose count 0.5/1.0. Average score (-0.06666666666666667)\n",
      "Win/lose count 2.5/6.0. Average score (-0.3)\n",
      "Win/lose count 0.5/3.0. Average score (-0.4666666666666667)\n",
      "Win/lose count 3.0/5.0. Average score (-0.6)\n",
      "Win/lose count 1.5/3.0. Average score (-0.7)\n",
      "Win/lose count 0.5/6.0. Average score (-1.0666666666666667)\n",
      "Win/lose count 1.0/0. Average score (-1.0)\n",
      "Final score: -1.0\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.1)\n",
    "agent_cnn = DQN_CNN(size, lr=1, epsilon=0.1, memory_size=1000, batch_size=128)\n",
    "agent_cnn.load(name_weights='./Results/cnn_trainmodel.h5',\n",
    "               name_model='./Results/cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=1, epsilon=0.1, memory_size=1000, batch_size=128)\n",
    "agent_cnn.load(name_weights='./Results/fc_trainmodel.h5',\n",
    "               name_model='./Results/fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn, env, epochs_test, prefix='./Results/cnn_test')\n",
    "print('\\nTest of the FC')\n",
    "test(agent_fc, env, epochs_test, prefix='./Results/fc_test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:45:25.447590Z",
     "start_time": "2019-02-26T22:45:25.443034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('./Results/cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:45:25.465099Z",
     "start_time": "2019-02-26T22:45:25.456264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('./Results/fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimised parameters, we observed:\n",
    "\\begin{itemize}\n",
    "    \\item The performance of the DQN with Convolutionnal networks performs in average better than the Fully Connected one.\n",
    "    \\item Also, we can observe that the agent get easily blocked in the corners and only explore one border There is a lack of exploration here.\n",
    "    \\item When the temperature increases, the score of the two agents increase also a lot. Indeed, there is much more food in the environment so it is easy for the agent to increase its score.\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:47:59.251719Z",
     "start_time": "2019-02-26T22:47:59.227679Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_explore(agent, env, epoch, prefix='', display=True, save=True):\n",
    "    \"\"\"Train the agent to explore env for the given number of epoch.\"\"\"\n",
    "    \n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        # Definition of epsilon\n",
    "        epsilon = 1 / (1 + e)**2\n",
    "        agent.set_epsilon(epsilon)\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "            \n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix + str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "        \n",
    "        if display:\n",
    "            print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "                  .format(e + 1, epoch, loss, win, lose, win-lose))\n",
    "        \n",
    "        if save:\n",
    "            agent.save(name_weights=prefix + 'model.h5', name_model=prefix + 'model.json')\n",
    "\n",
    "            \n",
    "class EnvironmentExploring(Environment):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1, train_binary=True):\n",
    "        super().__init__(grid_size=grid_size, max_time=max_time,\n",
    "                         temperature=temperature)\n",
    "        self.train_binary = train_binary\n",
    "        \n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2, :]= -1\n",
    "        self.position[:, 0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        \n",
    "        if action == 0: # Going up (or down on the image)\n",
    "            if self.x == self.grid_size - 3:\n",
    "                self.x = self.x - 1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1: # Going up on the image\n",
    "            if self.x == 2:\n",
    "                self.x = self.x + 1\n",
    "            else:\n",
    "                self.x = self.x - 1\n",
    "        elif action == 2: # Going right on the image\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3: # Going left on the image\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        \n",
    "        # Update of the reward\n",
    "        reward = 0\n",
    "        if self.train_binary:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        \n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),\n",
    "                               axis=2)\n",
    "        state = state[self.x-2:self.x+3, self.y-2:self.y+3, :]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "    \n",
    "        # Definition of board\n",
    "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time + 2, self.grid_size * self.scale, \n",
    "                                 self.grid_size * self.scale, 3))\n",
    "\n",
    "        malus[bonus > 0] = 0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "        \n",
    "        # Definition of malus_position\n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "        \n",
    "        # Definition of position\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x, self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size, 1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),\n",
    "                               axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:48:06.800582Z",
     "start_time": "2019-02-26T22:48:00.169951Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definition of the environment\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "\n",
    "# Definition of the agent\n",
    "dqn = lambda batch_size, memory_size, lr: DQN_CNN(size, lr=lr, epsilon=0.1,\n",
    "                                                  memory_size=memory_size,\n",
    "                                                  batch_size=batch_size, n_state=3)\n",
    "\n",
    "# Compute the GridSearch\n",
    "GridSearch(dqn, train_function=train_explore, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:01:47.639203Z",
     "start_time": "2019-02-26T22:48:20.452638Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/021 | Loss 0.0510 | Win/lose count 5.0/33.700000000000124 (-28.700000000000124)\n",
      "Epoch 002/021 | Loss 0.0472 | Win/lose count 10.0/24.20000000000007 (-14.20000000000007)\n",
      "Epoch 003/021 | Loss 0.0386 | Win/lose count 11.0/18.70000000000001 (-7.70000000000001)\n",
      "Epoch 004/021 | Loss 0.0341 | Win/lose count 11.0/18.59999999999998 (-7.59999999999998)\n",
      "Epoch 005/021 | Loss 0.0354 | Win/lose count 14.5/18.700000000000014 (-4.2000000000000135)\n",
      "Epoch 006/021 | Loss 0.0370 | Win/lose count 7.5/19.4 (-11.899999999999999)\n",
      "Epoch 007/021 | Loss 0.0354 | Win/lose count 16.5/14.499999999999972 (2.0000000000000284)\n",
      "Epoch 008/021 | Loss 0.0419 | Win/lose count 15.5/15.999999999999966 (-0.49999999999996625)\n",
      "Epoch 009/021 | Loss 0.0323 | Win/lose count 9.5/16.29999999999996 (-6.799999999999962)\n",
      "Epoch 010/021 | Loss 0.0358 | Win/lose count 6.5/18.599999999999994 (-12.099999999999994)\n",
      "Epoch 011/021 | Loss 0.0414 | Win/lose count 5.5/17.799999999999983 (-12.299999999999983)\n",
      "Epoch 012/021 | Loss 0.0295 | Win/lose count 21.0/16.199999999999964 (4.800000000000036)\n",
      "Epoch 013/021 | Loss 0.0297 | Win/lose count 3.0/18.499999999999993 (-15.499999999999993)\n",
      "Epoch 014/021 | Loss 0.0372 | Win/lose count 5.5/20.8 (-15.3)\n",
      "Epoch 015/021 | Loss 0.0199 | Win/lose count 14.0/15.199999999999962 (-1.199999999999962)\n",
      "Epoch 016/021 | Loss 0.0393 | Win/lose count 17.0/14.999999999999966 (2.0000000000000338)\n",
      "Epoch 017/021 | Loss 0.0439 | Win/lose count 15.5/17.39999999999999 (-1.8999999999999915)\n",
      "Epoch 018/021 | Loss 0.0255 | Win/lose count 9.0/17.99999999999999 (-8.99999999999999)\n",
      "Epoch 019/021 | Loss 0.0369 | Win/lose count 13.5/15.399999999999961 (-1.8999999999999613)\n",
      "Epoch 020/021 | Loss 0.0318 | Win/lose count 18.0/14.599999999999964 (3.400000000000036)\n",
      "Epoch 021/021 | Loss 0.0215 | Win/lose count 11.0/17.699999999999985 (-6.699999999999985)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=1, memory_size=1000, batch_size=128, n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore20.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T23:03:18.911205Z",
     "start_time": "2019-02-26T23:03:05.003191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 5.0/0. Average score (0.3333333333333333)\n",
      "Win/lose count 7.0/1.0. Average score (0.7333333333333333)\n",
      "Win/lose count 10.5/0. Average score (1.4333333333333333)\n",
      "Win/lose count 12.5/0. Average score (2.2666666666666666)\n",
      "Win/lose count 6.0/0. Average score (2.6666666666666665)\n",
      "Win/lose count 1.5/0. Average score (2.7666666666666666)\n",
      "Win/lose count 10.0/1.0. Average score (3.3666666666666667)\n",
      "Win/lose count 1.0/0. Average score (3.433333333333333)\n",
      "Win/lose count 9.5/0. Average score (4.066666666666666)\n",
      "Win/lose count 1.0/0. Average score (4.133333333333334)\n",
      "Win/lose count 4.5/0. Average score (4.433333333333334)\n",
      "Win/lose count 9.0/0. Average score (5.033333333333333)\n",
      "Win/lose count 6.5/0. Average score (5.466666666666667)\n",
      "Win/lose count 3.0/0. Average score (5.666666666666667)\n",
      "Win/lose count 11.0/0. Average score (6.4)\n",
      "Final score: 6.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFp9tZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9OCBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALnZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz8ZS8pY/so8NlBOhlWbQ+BTV0ni+BSUKFjikEI1as+JlKiRj9w9fmwKSbYKBOjhjcHBapRm+dDyTy36fj6Y5WZz1rGszlrVNZy5uVJoLRQkshnlIStJHNxdRx3SIVsVfwLVB8OG3BHYUBA2rh/TqmzohcwYdT8e41EzAmbDb1VGI2K++yYqaSoRgroy9ExzHeKYPtNP6MaXw3cxAm3cs8oBCxon3gpiDYYiWx7H7TUYKsfmjg1BA5mJ7IM3MuZw5HrKv32ghjWRz4tZkMyYawQfsl1dhiezPkdsWGCnTsn115c22YW0y4n1pL+iKbmpIe5UMdoVLpWIBMO30KeBAGQh1+Ez+sN1AaqpYPL6fIpKmPxxEfv6B73LxZ1hfpmhzY5C1SyfK40/3qHl1sGmqkeKYQlaz13unEuWKn9y/FYDWxYLH5bZtp00jBO60mQ9rTZOXuG1Aj5PzDZFZ03jlMSD86LLXCsoKGqAAATBOwVzQn+vteZjQj3VmgoeV+ERxke49FGNH+tR7NtVzGYMMkcj9uj/YZtvN8kErSFE89RGEgct7sljak8gFk03CUlHfTHUhYAw28eK6tZvzdhAr68axrzORAw2I5G90mlO1moQ6EX3DzpEYWyGwFekeT7w5twxc2RZnHgJ34FhyxBQqncP9R6zR2pTzjP1uF9tC+Aiz6AlF7xga9XdrPkY9jqDj+Tj5HhIX23f5Uc65p85bjpONcEHlDv3YmZ+Ag5SdVto9zwkiVQfNxDUkpuiDHFixccJvy0XPzQeehulAF2zw72tw8/2wLzX34ohFmCWn8w4BMd26wa5jhWDgZJWfJlFz9siUXcXJsNCll4C0zs60rO7JqvqRxCUyT0kp4rSQlzMBSB9ou1RU8OBZka0qnx1ZR6VkNgCFARRGNuxqUAAAvsAAAAUQZohbEM//p4QAQ74uH/gER9YTKgAAAAYQZpCPCGTKYQ3//6nhAAtnup+o40JDknBAAAAGEGaY0nhDyZTAhv//qeEAB0fYPXsz4IspwAAABlBmoRJ4Q8mUwId//6plgAOT8KMqszbMDxhAAAAJ0Gap0nhDyZTAh3//qmWACA9DufxCDb/8JVQzf/+h0o9/ayOTPR2vQAAABNBnsVFETwr/wA0ztTdOa2wkYydAAAAEAGe5mpCvwA0ztRyv7cP2cEAAAAiQZrrSahBaJlMCG///qeEAEO+SlzmWVrJ192tl/fc+07KCAAAABFBnwlFESwv/wAo9Bs8RkvS4AAAAA8Bnyh0Qr8ANMkohTBGG4EAAAAQAZ8qakK/ADdOqeS5nyUmgAAAAClBmy9JqEFsmUwIZ//+nhACoe8DauBTX1CvmWJYL5lk2DVYPkpztM4YqwAAABVBn01FFSwv/wBnFTQ0MT92sJwB4+UAAAAPAZ9sdEK/AFizJ3Bsl42/AAAADwGfbmpCvwCK7EeTA9e3JwAAADFBm3FJqEFsmUwUTDP//p4QBsqb6fiEdGr//iEJDxZ//w+aIs//4gx3fvC8fdlJzV/gAAAAEAGfkGpCvwFRseOV/bh83cAAAAAYQZuSSeEKUmUwIZ/+nhAHA64296b7OMb1AAAAGEGbs0nhDomUwIZ//p4QB1bnHgL7+iGnhAAAABtBm9RJ4Q8mUwIb//6nhAboAs2rqP0Cd/oafkAAAAAdQZv2SeEPJlMFETwz//6eEBucI59NR9bZ8rECZSUAAAAQAZ4VakK/AkiuDXHfiyu6YAAAABlBmhdJ4Q8mUwIb//6nhAIL46fR0KEhSO6BAAAAHkGaOUnhDyZTBRE8M//+nhAEd+IfxdHT65G7NisK2QAAABABnlhqQr8A7SuDXHiraO8gAAAAGEGaWknhDyZTAhn//p4QAunum+ipWa9+TwAAABhBmntJ4Q8mUwIb//6nhAB5/YPXsz4IrxcAAAAYQZqcSeEPJlMCG//+p4QAdz2D17M+CK8fAAAAKEGaoEnhDyZTAhn//p4QBDeV474hHeL//iEZKj//aW8/3UCtzTTayB0AAAAWQZ7eRRE8L/8AqFAgm5v1yHCX6P5aMAAAABABnv10Qr8AjvqJE+LMUbbQAAAAEAGe/2pCvwDiMweTA9e2toEAAAAcQZriSahBaJlMFPDP/p4QBDfiH+MV3I3ZsKo9IAAAABABnwFqQr8A4gRM030kHFFxAAAAGEGbA0nhClJlMCGf/p4QAtfum+ipWa9+XgAAABhBmyRJ4Q6JlMCGf/6eEAHZ9cbe9N91t6cAAAAZQZtFSeEPJlMCG//+p4QAef2D/CcFuhJdwQAAABhBm2ZJ4Q8mUwIb//6nhABRsVpBCJ/ltzMAAAAgQZuKSeEPJlMCGf/+nhABP/id+Cut1XaLDcCm0t2svMMAAAAWQZ+oRRE8L/8AMQI4xnLLjY+oJ82a/AAAABABn8d0Qr8AQV2pPK/JTaiwAAAAEAGfyWpCvwAtcbXb2sMkneEAAAAZQZvLSahBaJlMCGf//p4QAIt8Q863QMkRfAAAABhBm+xJ4QpSZTAhn/6eEACHfEPOt0DJEZwAAAAYQZoNSeEOiZTAhn/+nhAAg3xD+2Qx9YWfAAAAGEGaLknhDyZTAhv//qeEABasVpBCJ/lukwAAABlBmk9J4Q8mUwIb//6nhAAWz3U/UcaEh0nBAAAAGEGacUnhDyZTBRE8N//+p4QADuewf5gAgAAAAA8BnpBqQr8ADEAsaJXPMB8AAAAYQZqSSeEPJlMCHf/+qZYAC3C5BZzH4pOBAAAAG0GatknhDyZTAh3//qmWABECjqEGaBT6MfpmfAAAABBBntRFETwv/wAUdlioQV3gAAAAEAGe83RCvwAcWxWLY2VKWdEAAAAPAZ71akK/ABxOcNgcp0+AAAAAE0Ga+kmoQWiZTAh3//6plgAAlYEAAAAMQZ8YRREsL/8AALKBAAAADwGfN3RCvwAcVsDQ855eZQAAAA8BnzlqQr8AHE5w0SueXmUAAAATQZs+SahBbJlMCHf//qmWAACVgAAAAAxBn1xFFSwv/wAAsoEAAAAPAZ97dEK/ABxWwNDznl5lAAAADwGffWpCvwAcTnDRK55eZQAAABNBm2JJqEFsmUwId//+qZYAAJWAAAAADEGfgEUVLC//AACygQAAAA8Bn790Qr8AHFbA0POeXmUAAAAPAZ+hakK/ABxOcNErnl5lAAAAE0GbpkmoQWyZTAh3//6plgAAlYAAAAAMQZ/ERRUsL/8AALKBAAAADwGf43RCvwAcVsDQ855eZQAAAA8Bn+VqQr8AHE5w0SueXmUAAAATQZvqSahBbJlMCHf//qmWAACVgQAAAAxBnghFFSwv/wAAsoAAAAAPAZ4ndEK/ABxWwNDznl5lAAAADwGeKWpCvwAcTnDRK55eZQAAABNBmi5JqEFsmUwId//+qZYAAJWAAAAADEGeTEUVLC//AACygAAAAA8Bnmt0Qr8AHFbA0POeXmUAAAAPAZ5takK/ABxOcNErnl5lAAAAE0GackmoQWyZTAh3//6plgAAlYEAAAAMQZ6QRRUsL/8AALKAAAAADwGer3RCvwAcVsDQ855eZQAAAA8BnrFqQr8AHE5w0SueXmUAAAATQZq2SahBbJlMCHf//qmWAACVgAAAAAxBntRFFSwv/wAAsoAAAAAPAZ7zdEK/ABxWwNDznl5lAAAADwGe9WpCvwAcTnDRK55eZQAAABNBmvpJqEFsmUwId//+qZYAAJWBAAAADEGfGEUVLC//AACygQAAAA8Bnzd0Qr8AHFbA0POeXmUAAAAPAZ85akK/ABxOcNErnl5lAAAAE0GbPkmoQWyZTAh3//6plgAAlYAAAAAMQZ9cRRUsL/8AALKBAAAADwGfe3RCvwAcVsDQ855eZQAAAA8Bn31qQr8AHE5w0SueXmUAAAATQZtiSahBbJlMCHf//qmWAACVgAAAAAxBn4BFFSwv/wAAsoEAAAAPAZ+/dEK/ABxWwNDznl5lAAAADwGfoWpCvwAcTnDRK55eZQAAABNBm6ZJqEFsmUwId//+qZYAAJWAAAAADEGfxEUVLC//AACygQAAAA8Bn+N0Qr8AHFbA0POeXmUAAAAPAZ/lakK/ABxOcNErnl5lAAAAE0Gb6kmoQWyZTAh3//6plgAAlYEAAAAMQZ4IRRUsL/8AALKAAAAADwGeJ3RCvwAcVsDQ855eZQAAAA8BnilqQr8AHE5w0SueXmUAAAATQZouSahBbJlMCHf//qmWAACVgAAAAAxBnkxFFSwv/wAAsoAAAAAPAZ5rdEK/ABxWwNDznl5lAAAADwGebWpCvwAcTnDRK55eZQAAABNBmnJJqEFsmUwId//+qZYAAJWBAAAADEGekEUVLC//AACygAAAAA8Bnq90Qr8AHFbA0POeXmUAAAAPAZ6xakK/ABxOcNErnl5lAAAAE0GatkmoQWyZTAh3//6plgAAlYAAAAAMQZ7URRUsL/8AALKAAAAADwGe83RCvwAcVsDQ855eZQAAAA8BnvVqQr8AHE5w0SueXmUAAAATQZr6SahBbJlMCHf//qmWAACVgQAAAAxBnxhFFSwv/wAAsoEAAAAPAZ83dEK/ABxWwNDznl5lAAAADwGfOWpCvwAcTnDRK55eZQAAABNBmz5JqEFsmUwId//+qZYAAJWAAAAADEGfXEUVLC//AACygQAAAA8Bn3t0Qr8AHFbA0POeXmUAAAAPAZ99akK/ABxOcNErnl5lAAAAE0GbYkmoQWyZTAh3//6plgAAlYAAAAAMQZ+ARRUsL/8AALKBAAAADwGfv3RCvwAcVsDQ855eZQAAAA8Bn6FqQr8AHE5w0SueXmUAAAATQZumSahBbJlMCHf//qmWAACVgAAAAAxBn8RFFSwv/wAAsoEAAAAPAZ/jdEK/ABxWwNDznl5lAAAADwGf5WpCvwAcTnDRK55eZQAAABNBm+pJqEFsmUwId//+qZYAAJWBAAAADEGeCEUVLC//AACygAAAAA8Bnid0Qr8AHFbA0POeXmUAAAAPAZ4pakK/ABxOcNErnl5lAAAAE0GaLkmoQWyZTAh3//6plgAAlYAAAAAMQZ5MRRUsL/8AALKAAAAADwGea3RCvwAcVsDQ855eZQAAAA8Bnm1qQr8AHE5w0SueXmUAAAATQZpySahBbJlMCHf//qmWAACVgQAAAAxBnpBFFSwv/wAAsoAAAAAPAZ6vdEK/ABxWwNDznl5lAAAADwGesWpCvwAcTnDRK55eZQAAABNBmrZJqEFsmUwId//+qZYAAJWAAAAADEGe1EUVLC//AACygAAAAA8BnvN0Qr8AHFbA0POeXmUAAAAPAZ71akK/ABxOcNErnl5lAAAAE0Ga+kmoQWyZTAh3//6plgAAlYEAAAAMQZ8YRRUsL/8AALKBAAAADwGfN3RCvwAcVsDQ855eZQAAAA8BnzlqQr8AHE5w0SueXmUAAAATQZs+SahBbJlMCHf//qmWAACVgAAAAAxBn1xFFSwv/wAAsoEAAAAPAZ97dEK/ABxWwNDznl5lAAAADwGffWpCvwAcTnDRK55eZQAAABNBm2JJqEFsmUwId//+qZYAAJWAAAAADEGfgEUVLC//AACygQAAAA8Bn790Qr8AHFbA0POeXmUAAAAPAZ+hakK/ABxOcNErnl5lAAAAE0GbpkmoQWyZTAh3//6plgAAlYAAAAAMQZ/ERRUsL/8AALKBAAAADwGf43RCvwAcVsDQ855eZQAAAA8Bn+VqQr8AHE5w0SueXmUAAAATQZvqSahBbJlMCHf//qmWAACVgQAAAAxBnghFFSwv/wAAsoAAAAAPAZ4ndEK/ABxWwNDznl5lAAAADwGeKWpCvwAcTnDRK55eZQAAABNBmi5JqEFsmUwId//+qZYAAJWAAAAADEGeTEUVLC//AACygAAAAA8Bnmt0Qr8AHFbA0POeXmUAAAAPAZ5takK/ABxOcNErnl5lAAAAE0GackmoQWyZTAh3//6plgAAlYEAAAAMQZ6QRRUsL/8AALKAAAAADwGer3RCvwAcVsDQ855eZQAAAA8BnrFqQr8AHE5w0SueXmUAAAATQZq2SahBbJlMCHf//qmWAACVgAAAAAxBntRFFSwv/wAAsoAAAAAPAZ7zdEK/ABxWwNDznl5lAAAADwGe9WpCvwAcTnDRK55eZQAAABNBmvpJqEFsmUwId//+qZYAAJWBAAAADEGfGEUVLC//AACygQAAAA8Bnzd0Qr8AHFbA0POeXmUAAAAPAZ85akK/ABxOcNErnl5lAAAAE0GbPkmoQWyZTAh3//6plgAAlYAAAAAMQZ9cRRUsL/8AALKBAAAADwGfe3RCvwAcVsDQ855eZQAAAA8Bn31qQr8AHE5w0SueXmUAAAASQZtiSahBbJlMCG///qeEAAEnAAAADEGfgEUVLC//AACygQAAAA8Bn790Qr8AHFbA0POeXmUAAAAPAZ+hakK/ABxOcNErnl5lAAAAEkGbpkmoQWyZTAhn//6eEAAEfAAAAAxBn8RFFSwv/wAAsoEAAAAPAZ/jdEK/ABxWwNDznl5lAAAADwGf5WpCvwAcTnDRK55eZQAAABpBm+lLqEIQWyRGCCgH8gH9h4AhX/44QAARcQAAAChBngdFFSwr/wKvY+1BxN2qw0km5aqGByy1u80ok2LIAdk5Ond0CV2AAAAAIgGeKGpCvwKvY+1BxN2qw0km5aqGByy1u80oxh6soD3niVgAAAwAbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAACyp0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAqibWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKTW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACg1zdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABdhjdHRzAAAAAAAAALkAAAAFAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAMAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAMAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAABAAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAUAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFnAAAABgAAAAcAAAAHAAAAB0AAAArAAAAFwAAABQAAAAmAAAAFQAAABMAAAAUAAAALQAAABkAAAATAAAAEwAAADUAAAAUAAAAHAAAABwAAAAfAAAAIQAAABQAAAAdAAAAIgAAABQAAAAcAAAAHAAAABwAAAAsAAAAGgAAABQAAAAUAAAAIAAAABQAAAAcAAAAHAAAAB0AAAAcAAAAJAAAABoAAAAUAAAAFAAAAB0AAAAcAAAAHAAAABwAAAAdAAAAHAAAABMAAAAcAAAAHwAAABQAAAAUAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABcAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAFgAAABAAAAATAAAAEwAAAB4AAAAsAAAAJgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of the environment without training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3, train_binary=False)\n",
    "\n",
    "# Evaluation\n",
    "test(agent, env, epochs_test,prefix='./Results/cnn_test_explore')\n",
    "HTML(display_videos('./Results/cnn_test_explore14.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
